{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6de056-6d93-4a3b-87f3-574c4bbf3542",
   "metadata": {},
   "source": [
    "# News Summarizer Using Python and Tkinter\n",
    "\n",
    "## Overview\n",
    "This project is a **News Summarizer** that extracts and summarizes key details from an online news article. It utilizes **Natural Language Processing (NLP)** to generate concise summaries and analyze sentiment. The GUI is built using **Tkinter**, making it interactive and user-friendly.\n",
    "\n",
    "## Technologies Used\n",
    "- **Tkinter** – For creating the graphical user interface (GUI).\n",
    "- **Newspaper3k** – For extracting news articles from a given URL.\n",
    "- **TextBlob** – For performing sentiment analysis.\n",
    "- **NLTK (Natural Language Toolkit)** – A library for natural language processing tasks.\n",
    "\n",
    "## Installing Dependencies\n",
    "Before running the project, make sure you have the required libraries installed. You can install them using:\n",
    "\n",
    "```bash\n",
    "pip install newspaper3k textblob nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b94226-46f7-4590-a55e-20e90fc291cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f3f57-8810-486b-85e0-deb7b1fcaebc",
   "metadata": {},
   "source": [
    "The **Punkt tokenizer** is a pre-trained model used for sentence tokenization.  \n",
    "The `newspaper3k` library relies on it for processing article text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa209cf-6c91-4e56-9f61-1a82f2aa3a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7df3a-cf8f-40e7-90a6-79ed48100108",
   "metadata": {},
   "source": [
    "## Extracting and Summarizing an Article\n",
    "\n",
    "Now, let's extract an article from the web and generate a summary using **newspaper3k**.\n",
    "\n",
    "### Steps:\n",
    "1. **Define the URL** – Provide the link to the article.\n",
    "2. **Download and Parse** – Fetch and process the article's content.\n",
    "3. **Apply NLP** – Use newspaper3k’s built-in NLP to extract key details.\n",
    "4. **Print Results** – Display the title, authors, publication date, and summary.\n",
    "\n",
    "### Example: Machine Learning Wikipedia Page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "900cf31a-da11-483e-a20b-405ebbec0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7be453a-f0a7-4ea3-b235-ce9f4fb6ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine learning\n",
      "Authors: []\n",
      "Publication Date: None\n",
      "Summary: [14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n",
      "Robot learning [ edit ]Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[76][77] and finally meta-learning (e.g.\n",
      "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning.\n",
      "Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.\n",
      "[164][165]Embedded machine learning [ edit ]Embedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers, edge devices and microcontrollers.\n"
     ]
    }
   ],
   "source": [
    "print(F'Title: {article.title}')\n",
    "print(F'Authors: {article.authors}')\n",
    "print(F'Publication Date: {article.publish_date}')\n",
    "print(F'Summary: {article.summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c2977-99e0-4c85-b102-7fa291186ccb",
   "metadata": {},
   "source": [
    "## Sentiment Analysis  \n",
    "\n",
    "To determine the overall sentiment of the article, we use **TextBlob**, which analyzes the text and assigns a **polarity score**:  \n",
    "\n",
    "- **Positive** (> 0) → The article has a positive tone.  \n",
    "- **Negative** (< 0) → The article has a negative tone.  \n",
    "- **Neutral** (= 0) → The article has a neutral tone.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba9e3f0c-9642-4dfe-af03-a422fcd9bada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03427912972030616\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "analysis = TextBlob(article.text)\n",
    "print(analysis.polarity)\n",
    "print(f'Sentiment: {\"positive\" if analysis.polarity > 0 else \"negative\" if analysis.polarity < 0 else \"neutral\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f1ae9-5d93-4d95-bb80-2ece2671a03d",
   "metadata": {},
   "source": [
    "## Summarization Function  \n",
    "\n",
    "The **`summarize()`** function is used to extract, process, and display the article's details, including the title, author, publishing date, summary, and sentiment. Here's how the function works:  \n",
    "\n",
    "1. **Extracting URL**: The function gets the URL entered by the user from the text box (`utext`).\n",
    "2. **Downloading and Parsing**: It uses the `newspaper3k` library to download, parse, and analyze the article.\n",
    "3. **Displaying Information**: The article's title, author, publication date, and summary are displayed in the GUI text fields.\n",
    "4. **Sentiment Analysis**: The function uses **TextBlob** to determine the article's sentiment based on the polarity score.\n",
    "5. **Disabling Text Fields**: After displaying the results, the text fields are set back to a disabled state to prevent editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e517d438-0fa2-427a-816e-8a630e59f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize():\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    url = utext.get(\"1.0\", \"end\").strip()\n",
    "\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "\n",
    "    title.config(state=\"normal\")\n",
    "    author.config(state=\"normal\")\n",
    "    publication.config(state=\"normal\")\n",
    "    summary.config(state=\"normal\")\n",
    "    sentiment.config(state=\"normal\")\n",
    "\n",
    "    title.delete(\"1.0\", \"end\")\n",
    "    title.insert(\"1.0\", article.title)\n",
    "\n",
    "    author.delete(\"1.0\", \"end\")\n",
    "    author.insert(\"1.0\", article.authors if article.authors else \"N/A\")\n",
    "\n",
    "    publication.delete(\"1.0\", \"end\")\n",
    "    publication.insert(\"1.0\", article.publish_date if article.publish_date else \"N/A\")\n",
    "\n",
    "    summary.delete(\"1.0\", \"end\")\n",
    "    summary.insert(\"1.0\", article.summary)\n",
    "\n",
    "    analysis = TextBlob(article.text)\n",
    "    sentiment.delete(\"1.0\", \"end\")\n",
    "    sentiment.insert(\"1.0\", f'Polarity {analysis.polarity}, Sentiment: {\"positive\" if analysis.polarity > 0 else \"negative\" if analysis.polarity < 0 else \"neutral\"}')\n",
    "\n",
    "    title.config(state=\"disabled\")\n",
    "    author.config(state=\"disabled\")\n",
    "    publication.config(state=\"disabled\")\n",
    "    summary.config(state=\"disabled\")\n",
    "    sentiment.config(state=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d7169-0baf-4b75-a240-0af686007b45",
   "metadata": {},
   "source": [
    "## Building the Graphical User Interface (GUI)  \n",
    "\n",
    "The application uses **Tkinter** to create a simple and interactive GUI for summarizing news articles.  \n",
    "\n",
    "### **GUI Components:**\n",
    "- **Title, Author, Publishing Date, Summary, Sentiment Analysis** → Display extracted details.\n",
    "- **URL Input Field** → Users enter the article link.\n",
    "- **Summarize Button** → Triggers the summarization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c575fbb-2201-4d01-97b1-5f30dcd68e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"News Summarizer\")\n",
    "root.geometry(\"1200x600\")\n",
    "\n",
    "tlabel = tk.Label(root, text=\"Title\")\n",
    "tlabel.pack()\n",
    "\n",
    "title = tk.Text(root, height=1, width=140)\n",
    "title.config(state=\"disabled\", bg=\"#dddddd\")\n",
    "title.pack()\n",
    "\n",
    "alabel = tk.Label(root, text=\"Author\")\n",
    "alabel.pack()\n",
    "\n",
    "author = tk.Text(root, height=1, width=140)\n",
    "author.config(state=\"disabled\", bg=\"#dddddd\")\n",
    "author.pack()\n",
    "\n",
    "plabel = tk.Label(root, text=\"Publishing Date\")\n",
    "plabel.pack()\n",
    "\n",
    "publication = tk.Text(root, height=1, width=140)\n",
    "publication.config(state=\"disabled\", bg=\"#dddddd\")\n",
    "publication.pack()\n",
    "\n",
    "slabel = tk.Label(root, text=\"Summary\")\n",
    "slabel.pack()\n",
    "\n",
    "summary = tk.Text(root, height=20, width=140)\n",
    "summary.config(state=\"disabled\", bg=\"#dddddd\")\n",
    "summary.pack()\n",
    "\n",
    "selabel = tk.Label(root, text=\"Sentiment Analysis\")\n",
    "selabel.pack()\n",
    "\n",
    "sentiment = tk.Text(root, height=1, width=140)\n",
    "sentiment.config(state=\"disabled\", bg=\"#dddddd\")\n",
    "sentiment.pack()\n",
    "\n",
    "ulabel = tk.Label(root, text=\"URL\")\n",
    "ulabel.pack()\n",
    "\n",
    "utext = tk.Text(root, height=1, width=140)\n",
    "utext.pack()\n",
    "\n",
    "btn = tk.Button(root, text=\"Summarize\", command=summarize)\n",
    "btn.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
